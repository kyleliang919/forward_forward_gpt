# forward_forward_gpt
## Description

Exploring training large language model with [Hinton's forward forward algorithm](https://www.cs.toronto.edu/~hinton/FFA13.pdf).

Based on my rudimentary understanding of the forward forward algorithm, it's a "GAN" with generator and discriminator sharing the same encoder, which is being trained only with the discriminator objective. The "goodness" function is equivalent to a per layer discriminator loss function, where negative sample (in our case generated by GPT itself) 's "goodness" minimize and maximize the positive activation.

## Problems
* Forward forward can't train embedding, simply because there is not really a difference between "positive" and "negative", the current hack is adding another "skip connection" from the embeddings directly to the end loss.

### Dependencies

* transformer
* torch
* tqdm

### [Key Changes]
* [Generating negative samples](https://github.com/kyleliang919/forward_forward_gpt/blob/a60b8fd209f9f822bc4e9e3169255cc09aaccc1e/src/trainer.py#L45)
```
    with torch.no_grad():
        model.eval()
        generated_ids = model.generate(inputs['input_ids'].to(model.device), attention_mask = inputs['attention_mask'].to(model.device), max_length = inputs['input_ids'].shape[-1] * 2)
```

* [Local loss]((https://github.com/kyleliang919/forward_forward_gpt/blob/a60b8fd209f9f822bc4e9e3169255cc09aaccc1e/src/modeling_gpt2.py#L440)) in GPT Encoder Block 
```
    if self.training:
        positive = hidden_states[:hidden_states.shape[0]//2]
        negative = hidden_states[hidden_states.shape[0]//2:]
        loss = torch.log(1 + torch.exp(torch.cat([
                -positive + self.threshold,
                negative - self.threshold]))).mean()
        loss.backward()
```

### Run Example

```
python src/main.py
```

## Authors
[@KyleLiang5](https://twitter.com/KyleLiang5)

## License

This project is licensed under the MIT License - see the LICENSE.md file for details

## Acknowledgments